[readme.md](https://github.com/user-attachments/files/22362435/readme.md)
# Peptide Prediction Benchmark
## ğŸ“Project Structure
~~~
pep_prediction_bench/
â”œâ”€â”€ data/                      # Data storage directory
â”‚   â”œâ”€â”€ Binary_Classification/ # Binary classification task data               
â”‚   â””â”€â”€ Regression/            # Regression task data
â”‚
â”œâ”€â”€ data_split/
â”‚   â”œâ”€â”€random_split.py         # Random split
â”‚   â””â”€â”€similar_split.py        # Similarity based split
â”‚
â”œâ”€â”€ feature/                   # Feature engineering module
â”‚   â”œâ”€â”€ onehot.py              # One-Hot encoding
â”‚   â”œâ”€â”€ descriptor.py          # Molecular descriptor encoding
â”‚   â””â”€â”€ integer.py
â”‚     
â”œâ”€â”€ MODEL/                     # Pretrained model storage               
â”‚   â”œâ”€â”€ prot_bert/             # PepBERT model
â”‚   â””â”€â”€ esm2_t12_35M_UR50D/    # ESM model
â”‚
â”œâ”€â”€ model/                     # Model architecture definitions
â”‚   â”œâ”€â”€ base.py                #
â”‚   â”œâ”€â”€ factory.py             # 
â”‚   â”œâ”€â”€ rf.py                  # Random Forest model
â”‚   â”œâ”€â”€ svm.py                 # Support Vector Machine model
â”‚   â”œâ”€â”€ xgb.py                 # XGBoost model
â”‚   â”œâ”€â”€ lstm.py                # LSTM model
â”‚   â”œâ”€â”€ transformer.py         # Transformer model
â”‚   â”œâ”€â”€ esm.py                 # ESM model
â”‚   â”œâ”€â”€ pepbert.py             # PepBERT model
â”‚   â””â”€â”€ predict_model.py       # Prediction Head
â”‚
â”œâ”€â”€ utils/                     # Utility functions  
â”‚   â””â”€â”€ metrics.py             # Evaluation metrics
â”‚                      
â”œâ”€â”€ saved_models/              # Path for saving trained models     
â”œâ”€â”€ train.py                   # Main training script           
â”œâ”€â”€ dataset.py                 # Data loader
â”œâ”€â”€ model_manager.py           # Model management tool
â””â”€â”€ test.py                    # Testing and evaluation script
~~~      

## ğŸ“ŠData Introduction
### Data Sources
The peptide data used in this project comes from public databases and experimental measurements, including binary classification datasets and regression datasets:
#### Binary Classification Datasets
##### 1.Antidiabetic Peptide(ADP)
- **Source**ï¼š*Discovery of potential antidiabetic peptides using deep learning*
- **Positive samples**ï¼š418
- **Negative samples**ï¼š5250
- **Length range**ï¼š4-99
- **Description**ï¼šContains only natural amino acids

##### 2.Antimicrobial Peptide(amp)
- **Source**ï¼šPositive samples were integrated from the APD3, DBAASP, and DRAMP databases, retaining only sequences with both N- and C-termini being free or empty, followed by merging and deduplication. Negative samples were collected from the UniProt database by applying the â€œsubcellular locationâ€ filter set to â€œcytoplasm,â€ with sequence length less than 183. Entries containing any of the following keywords were removed: antimicrobial, antibiotic, antiviral, antifungal, effector, excreted. The filtering was performed according to the paper *Identification of antimicrobial peptides from the human gut microbiome using deep learning*.
- **Positive samples**ï¼š28756
- **Negative samples**ï¼š28756
- **Length range**ï¼š1-183
- **Description**ï¼šContains only natural amino acids

##### 3.Antioxidant Peptide(AOPP)
- **Source**ï¼šAntioxidant Peptide Prediction database
- **Positive samples**ï¼š1586
- **Negative samples**ï¼š1578
- **Length range**ï¼š2-20
- **Description**ï¼šContains only natural amino acids

##### 4.Self-assembling Peptide(assem)
- **Source**ï¼š*Efficient prediction of peptide self-assembly through equential and graphical encoding* and *Reshaping the discovery of self-assembling peptides with generative AI guided by hybrid deep learning*
- **Positive samples**ï¼š15007
- **Negative samples**ï¼š26697
- **Length range**ï¼š3-24
- **Description**ï¼šContains only natural amino acids

##### 5.Bloodâ€“Brain Barrier Penetrating Peptide(BBB)
- **Source**ï¼š*Improved prediction and characterization of blood-brain barrier penetrating peptides using estimated propensity scores of dipeptides*
- **Positive samples**ï¼š265
- **Negative samples**ï¼š257
- **Length range**ï¼š4-30
- **Description**ï¼šContains only natural amino acids

##### 6.Cell-Penetrating Peptide(CPP)
- **Source**ï¼š*StackCPPred: a stacking and pairwise energy  content-based prediction of cell-penetrating peptides  and their uptake efficiency*
- **Positive samples**ï¼š462
- **Negative samples**ï¼š462
- **Length range**ï¼š4-61
- **Description**ï¼šContains only natural amino acids

##### 7.Dipeptidyl Peptidase IV Inhibitory Peptide(DPPIV)
- **Source**ï¼š*StackDPPIV: A novel computational approach for accurate prediction of dipeptidyl peptidase IV (DPP-IV) inhibitory peptides*
- **Positive samples**ï¼š664
- **Negative samples**ï¼š665
- **Length range**ï¼š2-90
- **Description**ï¼šContains only natural amino acids

##### 8.Hemolysis Peptide(hemo)
- **Source**ï¼š*PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction*
- **Positive samples**ï¼š1826
- **Negative samples**ï¼š7490
- **Length range**ï¼š1-190
- **Description**ï¼šContains only natural amino acids

##### 9.Nonfouling Peptide(human)
- **Source**ï¼š*PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction*
- **Positive samples**ï¼š3600
- **Negative samples**ï¼š13585
- **Length range**ï¼š4-198
- **Description**ï¼šContains only natural amino acids

##### 10.Neuropeptide(NEU)
- **Source**ï¼š*NeuroPred-PLM: an interpretable and robust model for neuropeptide prediction by protein language model*
- **Positive samples**ï¼š4393
- **Negative samples**ï¼š4306
- **Length range**ï¼š4-99
- **Description**ï¼šContains only natural amino acids

##### 11.Solubility Peptide(souble)
- **Source**ï¼š*PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction*
- **Positive samples**ï¼š8785
- **Negative samples**ï¼š9668
- **Length range**ï¼š4-198
- **Description**ï¼šContains only natural amino acids

##### 12.Toxic Peptide(toxic)
- **Source**ï¼šToxinPred2 dataset
- **Positive samples**ï¼š1052
- **Negative samples**ï¼š464
- **Length range**ï¼š1-200
- **Description**ï¼šContains only natural amino acids

#### Regression Datasets
##### 1.EC
- **Source**ï¼š*BERT-AmPEP60: A BERT-Based Transfer Learning Approach to Predict the Minimum Inhibitory Concentrations of Antimicrobial Peptides for Escherichia coli and Staphylococcus aureus*
- **Number of samples**ï¼š4042
- **Length range**ï¼š60
- **Description**ï¼šContains only natural amino acids

##### 2.SA
- **Source**ï¼š*BERT-AmPEP60: A BERT-Based Transfer Learning Approach to Predict the Minimum Inhibitory Concentrations of Antimicrobial Peptides for Escherichia coli and Staphylococcus aureus*
- **Number of samples**ï¼š3275
- **Length range**ï¼š60
- **Description**ï¼šContains only natural amino acids

##### 3.Hemolysis Peptide
- **Source**ï¼šHemoPI2 - Hemolytic Activity Prediction
- **Number of samples**ï¼š1926
- **Length range**ï¼š39
- **Description**ï¼šContains only natural amino acids

### Data Format
The data is stored in CSV format and contains the following columns:
~~~
id,peps,label
1527,FLGAILKIGHALAKTVLPMVTNAFKPKQ,0.0
173,SPLGQSQPTVAGQPSARPAAEEYGYIVTDQKPLSLAAGVK,1.0
1032,QGVRNSQSCRRNKGICVPIRCPGSMRQIGTCLGAQVKCCRRK,5.161810388853155
~~~

### Description of Columns
- **id column**ï¼šSerial number, no special meaning
- **peps column**ï¼šPeptide sequence represented by amino acid single-letter codes
- **label column**ï¼šIndicates whether the peptide has a certain function or the strength of its activity


## ğŸš€Quick Start
### Install Dependencies
```bash
conda create -n pepbench python=3.10 -y
conda activate pepbench
pip install -r requirements.txt
```
### Dataset Splitting
```bash
python random_split.py --data_path data/Binary_Classification/ADP.csv --random_state 111 # Random split
python similar_split.py --data_path data/Binary_Classification/ADP.csv --threshold 0.8 --random_state 111 # Similarity-based split
```
### Feature Extraction
```python
# one-hot
encoder = OneHotEncoder(max_len=max_len, flatten=True)
features = encoder.encode(ssequences)

# descriptor
encoder = PeptidyDescriptorEncoder()
features = encoder.encode(sequences)
```
### Train Models
~~~bash
python train.py --task classification --model rf --feature_type onehot --random_state 111 --train_path data/Binary_Classification/splitter111/ADP_train.csv --val_path data/Binary_Classification/splitter111/ADP_val.csv --max_len 41 --data_name ADP
~~~
### Test Models
~~~bash
python test.py --task classification --model rf --feature_type onehot --model_path saved_models/BEST_rf_onehot_classification_ADP_seed111.pkl --test_path data/Binary_Classification/splitter111/ADP_test.csv --max_len 41
~~~

## ğŸ“„License
Distributed under the Apache License 2.0.  
See [LICENSE](LICENSE) for details.

Copyright 2025 Li Pengyong.

